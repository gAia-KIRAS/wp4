{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from matplotlib.colors import ListedColormap\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pickle\n",
    "import sklearn.feature_selection as fs\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "import itertools\n",
    "# pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_inventory(path, crs=4326, date_start='2017-10-01', date_end='2023-01-01'):\n",
    "    inventory = gpd.read_file(path)\n",
    "    inventory = inventory.to_crs(crs)\n",
    "    inventory = inventory[['OBJEKTID', 'EREIG_ZEIT', 'geometry']]\n",
    "    date1 = pd.to_datetime(inventory['EREIG_ZEIT'], errors='coerce', format='%Y')\n",
    "    date2 = pd.to_datetime(inventory['EREIG_ZEIT'], errors='coerce', format='%m.%Y')\n",
    "    date3 = pd.to_datetime(inventory['EREIG_ZEIT'], errors='coerce', format='%d.%m.%Y')\n",
    "    date3 = date3.fillna(date2)\n",
    "    date3 = date3.fillna(date1)\n",
    "    inventory['EREIG_ZEIT'] = date3\n",
    "    return inventory[inventory.EREIG_ZEIT >= date_start][inventory.EREIG_ZEIT < date_end]\n",
    "\n",
    "def read_weather(path):\n",
    "    df_won_weather = gpd.read_parquet(path)\n",
    "    df_won_weather['weath_geom'] = df_won_weather.geometry     # save geo point of weather data\n",
    "    return df_won_weather\n",
    "\n",
    "def merge_weather_landslide(landslide_data: pd.DataFrame, weather_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Merging of landslide point and unique geo points from weather data.\n",
    "    Sets the landslide column in weather data to 0, for EREIG_ZEIT date - 1\n",
    "    \"\"\"\n",
    "    common_points = gpd.sjoin_nearest(landslide_data, weather_data[weather_data.time == \"2018-04-01\"], how='inner', lsuffix='inv', rsuffix='weather')\n",
    "    land_filtered = common_points[['OBJEKTID', 'EREIG_ZEIT', 'geometry', 'weath_geom']].reset_index(drop=True)\n",
    "    \n",
    "    weather_data[\"landslide\"] = 0\n",
    "    wd_land_only = pd.merge(weather_data, land_filtered, left_on='geometry', right_on='weath_geom').drop(['weath_geom_x', 'weath_geom_y'], axis=1)\n",
    "    wd_land_only = wd_land_only.rename({'geometry_x':'geometry', 'geometry_y':'inv_geom'}, axis=1)\n",
    "    wd_land_only.loc[wd_land_only.time == wd_land_only.EREIG_ZEIT, 'landslide'] = 1\n",
    "    return wd_land_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(time_window: pd.DataFrame, month_time: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculation of time-wise features based on available weather conditions\n",
    "\n",
    "    Arguments: \n",
    "        time_window: df of smaller time-period: usually 14 days\n",
    "        month_time: df of larger time-period: usually 30 days\n",
    "    Returns:\n",
    "        dictionary of calculated weather features\n",
    "    \"\"\"\n",
    "    return {'prec_max':[time_window.prec.max()],\n",
    "            'prec_mean':[time_window.prec.mean()],\n",
    "            'prec_min':[time_window.prec.min()],\n",
    "            'prec_kurt':[time_window.prec.kurtosis()],\n",
    "            'prec_kurt_month':[month_time.prec.kurtosis()],\n",
    "            'sum_prec':[time_window.prec.sum()],\n",
    "            'sum_prec_month':[month_time.prec.sum()],\n",
    "            'prec_skew':[time_window.prec.skew()],\n",
    "            'prec_skew_month':[month_time.prec.skew()],\n",
    "\n",
    "            'wind_max':[time_window.wind.max()],\n",
    "            'wind_max_month':[month_time.wind.max()],\n",
    "            'wind_mean':[time_window.wind.mean()],\n",
    "            'wind_min':[time_window.wind.min()],\n",
    "            'wind_skew':[time_window.wind.skew()],\n",
    "            'wind_skew_month':[month_time.wind.skew()],\n",
    "            'wind_kurt':[time_window.wind.kurtosis()],\n",
    "            'wind_kurt_month':[month_time.wind.kurtosis()],\n",
    "            'wind_light':[len(time_window[time_window.wind <= 5])],\n",
    "            'wind_mod':[len(time_window[(time_window.wind > 5) & (time_window.wind <= 11)])],\n",
    "            'wind_strong':[len(time_window[(time_window.wind > 11) & (time_window.wind <= 17)])],\n",
    "            'wind_sev':[len(time_window[(time_window.wind > 17) & (time_window.wind <= 23)])],\n",
    "            'wind_extr':[len(time_window[time_window.wind > 23])],\n",
    "            \n",
    "            'mslp_min':[time_window.mslp.min()],\n",
    "            'mslp_mean':[time_window.mslp.mean()],\n",
    "            'mslp_max':[time_window.mslp.max()],\n",
    "            'mslp_high':[len(time_window[time_window.mslp >= 102000])],\n",
    "            'mslp_norm':[len(time_window[(time_window.mslp > 101300) & (time_window.mslp < 102000)])],\n",
    "            'mslp_shall':[len(time_window[(time_window.mslp > 100000) & (time_window.mslp <= 101300)])],\n",
    "            'mslp_low':[len(time_window[(time_window.mslp > 98000) & (time_window.mslp <= 100000)])],\n",
    "            'mslp_verylow':[len(time_window[time_window.mslp <= 98000])],\n",
    "            'mslp_skew':[time_window.mslp.skew()],\n",
    "            'mslp_skew_month':[month_time.mslp.skew()],\n",
    "            'mslp_kurt':[time_window.mslp.kurtosis()],\n",
    "            'mslp_kurt_month':[month_time.mslp.kurtosis()],\n",
    "\n",
    "            'relhum_min':[time_window.relative_humidity.min()],\n",
    "            'relhum_mean':[time_window.relative_humidity.mean()],\n",
    "            'relhum_max':[time_window.relative_humidity.max()],\n",
    "            'relhum_veryhigh':[len(time_window[time_window.relative_humidity > 80])],\n",
    "            'relhum_high':[len(time_window[(time_window.relative_humidity >= 60) & (time_window.relative_humidity <= 80)])],\n",
    "            'relhum_norm':[len(time_window[(time_window.relative_humidity >= 30) & (time_window.relative_humidity < 60)])],\n",
    "            'relhum_low':[len(time_window[time_window.relative_humidity < 30])],\n",
    "            'relhum_skew':[time_window.relative_humidity.skew()],\n",
    "            'relhum_skew_month':[month_time.relative_humidity.skew()],\n",
    "            'relhum_kurt':[time_window.relative_humidity.kurtosis()],\n",
    "            'relhum_kurt_month':[month_time.relative_humidity.kurtosis()],\n",
    "\n",
    "            'temp_skew':[time_window.temp.skew()],\n",
    "            'temp_skew_month':[month_time.temp.skew()],\n",
    "            'temp_max':[time_window.temp.max()],\n",
    "            'temp_min':[time_window.temp.min()],\n",
    "            'temp_mean':[time_window.temp.mean()],\n",
    "            'temp_mean_month':[month_time.temp.mean()],\n",
    "            'temp_kurt':[time_window.temp.kurtosis()],\n",
    "            'temp_kurt_month':[month_time.temp.kurtosis()],\n",
    "            'temp_std':[time_window.temp.std()],\n",
    "            }\n",
    "\n",
    "def create_df_for_landsl(df_w_data, uniquep_won, n_days:int = 14, start_point: int =0, final_point:int =None, step:int =3, num_from_one:int =5):\n",
    "    \"\"\"\n",
    "    Creates a dataframe of weather analysis data on landslide points.\n",
    "\n",
    "    Arguments:\n",
    "        uniquep_won: all unique landslide spatial points\n",
    "        n_days: number of days for the first time window\n",
    "        start_point [int]: the starting point among unique points of landslide event, index of uniquep_won\n",
    "        final_point [int]: the last landslide among unique points of landslide event considered for creating a dataset, index of uniquep_won\n",
    "        step: number of days to step back from landslide event for creating non-landlide statistics\n",
    "        num_from_one: how many time entries to create for non-landslide events\n",
    "    Returns:\n",
    "        Dataframe of processed weather conditions with landslide and non-landslide points as target variable \n",
    "        and calculated weather features before event as independent variables.\n",
    "    \"\"\"\n",
    "    new_entries = []\n",
    "    if final_point == None:\n",
    "        final_point = len(uniquep_won)\n",
    "\n",
    "    for i in range(start_point, final_point):\n",
    "        point = uniquep_won[i]\n",
    "        X_data = df_w_data.loc[df_w_data['geometry'].isin([point])]\n",
    "        X_data = X_data.reset_index(drop=True)\n",
    "\n",
    "        land_dates = X_data[X_data.landslide == 1]\n",
    "        try:\n",
    "            print(land_dates.index)\n",
    "            for idx in land_dates.index:\n",
    "                for j in range(0, num_from_one):\n",
    "                    deviation = j*step\n",
    "\n",
    "                    time_window = X_data.iloc[idx-n_days - deviation : idx - deviation]\n",
    "                    month_time = X_data.iloc[idx-30 - deviation : idx - deviation]\n",
    "\n",
    "                    d = calculate_features(time_window, month_time)\n",
    "                    d['landslide'] = X_data.iloc[idx - deviation].landslide\n",
    "                    new_entries.append(pd.DataFrame(d))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    point_data = pd.concat(new_entries, ignore_index=True)\n",
    "    return point_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data(data: pd.DataFrame, new_feats: list, test_size: float=0.2):\n",
    "    \"\"\"\n",
    "    Create training/test sets proportionally to the landslide and non-landslide events\n",
    "\n",
    "    Arguments:\n",
    "        new_feats: list of features used for the X data.\n",
    "    Returns:\n",
    "        X_train, X_val, y_train, y_val\n",
    "    \"\"\"\n",
    "    analys_l = data[data.landslide == 1]\n",
    "    analys_wl = data[data.landslide == 0]\n",
    "\n",
    "    X_data_l = analys_l[new_feats]\n",
    "    X_data_wl = analys_wl[new_feats]\n",
    "    y_data_l = analys_l[[\"landslide\"]]\n",
    "    y_data_wl = analys_wl[[\"landslide\"]]\n",
    "\n",
    "\n",
    "    X_train_l, X_val_l, y_train_l, y_val_l = train_test_split(X_data_l, y_data_l, test_size=test_size, random_state=1423)\n",
    "    X_train_wl, X_val_wl, y_train_wl, y_val_wl = train_test_split(X_data_wl, y_data_wl, test_size=test_size, random_state=1423)\n",
    "    X_train, X_val, y_train, y_val = pd.concat([X_train_l, X_train_wl]), pd.concat([X_val_l, X_val_wl]), pd.concat([y_train_l, y_train_wl]), pd.concat([y_val_l, y_val_wl])\n",
    "\n",
    "    print((X_train.shape, X_val.shape, y_train.shape, y_val.shape))\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_first_features(f_num: int, X, y):\n",
    "    \"\"\"\n",
    "    Feature selection based on f_classif\n",
    "\n",
    "    Arguments:\n",
    "        f_num: number of independent features that should be left\n",
    "    \"\"\"\n",
    "    fclass = SelectKBest(f_classif, k=f_num).fit(X, y)\n",
    "    X_new = pd.DataFrame(fclass.transform(X))\n",
    "    mask = fclass.get_support()\n",
    "    new_features = X.columns[mask]\n",
    "    X_new = X[new_features]\n",
    "    full_up_data = X_new.merge(y, left_index=True, right_index=True)\n",
    "    return full_up_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_feat_sel(full_train_data, new_feats: list, statistics_try: dict, num: int, indx: int =0, final: int =20):\n",
    "    \"\"\"\n",
    "    Feature selection based on checking all possible options by eliminating 1 feature at a time\n",
    "\n",
    "    Arguments:\n",
    "        new_feats [list]: features of training dataset to consider for feature selection\n",
    "        statistics_try [dict]: statistics of trying the features\n",
    "        num: number of features to consider for the first run. Recommended: len(new_feats)-1\n",
    "        indx: index of the features combinations to be reduced. Initialised: 0\n",
    "        final: target number of number of features\n",
    "    \n",
    "    Returns:\n",
    "        a dataframe of ststistics of feature elimination\n",
    "    \"\"\"\n",
    "    if num == final:\n",
    "        return \n",
    "\n",
    "    # create all possible combinations of eliminating column/-s to reach n number of columns from current one\n",
    "    all_cols = full_train_data[new_feats]\n",
    "    combinations = list(itertools.combinations(all_cols, num))\n",
    "    print(num)\n",
    "    print(f\"len combs = {len(combinations)}\")\n",
    "\n",
    "    for j in range(0, len(combinations)):\n",
    "        X_train, X_val, y_train, y_val = divide_data(full_train_data, list(combinations[j]))\n",
    "        y_train = y_train['landslide']\n",
    "        y_val = y_val['landslide']\n",
    "        statistics_try['prev_index'].append(indx)\n",
    "        statistics_try['features'].append(list(X_train.columns.values))\n",
    "        rf = RandomForestClassifier(n_estimators = 600, random_state=42, max_depth=6, class_weight=\"balanced\") # 6 - 66.3 recall\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_rf = rf.predict(X_train)\n",
    "        class_report_train = classification_report(y_train, y_pred_rf, output_dict=True)\n",
    "        statistics_try['rf_acc_train'].append(class_report_train['accuracy'])\n",
    "        statistics_try['rf_prec_1_train'].append(class_report_train['1']['precision'])\n",
    "        statistics_try['rf_rec_1_train'].append(class_report_train['1']['recall'])\n",
    "        statistics_try['rf_f1_1_train'].append(class_report_train['1']['f1-score'])\n",
    "\n",
    "        y_pred_rf_val = rf.predict(X_val)\n",
    "        class_report = classification_report(y_val, y_pred_rf_val, output_dict=True)\n",
    "        statistics_try['rf_acc'].append(class_report['accuracy'])\n",
    "        statistics_try['rf_prec_1'].append(class_report['1']['precision'])\n",
    "        statistics_try['rf_rec_1'].append(class_report['1']['recall'])\n",
    "        statistics_try['rf_f1_1'].append(class_report['1']['f1-score'])\n",
    "    new_stats = pd.DataFrame.from_dict(statistics_try)\n",
    "\n",
    "    # sort the results of RandomForest model for all tested combinations; choose 2 best\n",
    "    indexes = new_stats[new_stats.prev_index == indx].sort_values(by=['rf_rec_1', 'rf_f1_1', 'rf_prec_1', 'rf_acc', 'rf_f1_1_train', 'rf_prec_1_train', 'rf_rec_1_train', 'rf_acc_train'], ascending=False).head(2).index\n",
    "    print(f\"indxs = {indexes}\")\n",
    "\n",
    "    # for the 2 best run the elimination of 1 more feature\n",
    "    for idx in indexes:\n",
    "        if len(new_stats.iloc[idx].features) < len(new_feats):\n",
    "            print(f\"idx = {idx}\")\n",
    "            statistics_try = run_feat_sel(full_train_data, new_stats.iloc[idx].features.copy(), statistics_try, num-1, idx, final)\n",
    "    return statistics_try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge weather and landslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YKlysa\\AppData\\Local\\anaconda3\\envs\\weather\\lib\\site-packages\\geopandas\\geodataframe.py:1415: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super().__getitem__(key)\n",
      "c:\\Users\\YKlysa\\AppData\\Local\\anaconda3\\envs\\weather\\lib\\site-packages\\geopandas\\array.py:344: UserWarning: Geometry is in a geographic CRS. Results from 'sjoin_nearest' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "df_won_weather = read_weather(\"gdf_weather_carinthia.parquet\")\n",
    "another_inv3_filt = read_inventory(\"..\\\\..\\\\wp5\\\\Daten Massenbewegungen\\Massenbewegungen im Detail\\\\Massenbewegungen_im_Detail.shp\")\n",
    "ww_land_only = merge_weather_landslide(another_inv3_filt, df_won_weather)\n",
    "\n",
    "uniquep_won = ww_land_only.geometry.unique()\n",
    "print(len(uniquep_won))\n",
    "\n",
    "# ww_land_only.to_parquet('curr_ll_from_recent_points_inv_20171001_2022.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_landsl = gpd.read_parquet('curr_ll_from_recent_points_inv_20171001_2022.parquet')\n",
    "uniquep_won = curr_landsl.geometry.unique()\n",
    "analysis_data = create_df_for_landsl(curr_landsl, uniquep_won, step=30, num_from_one=5)\n",
    "# analysis_data.to_parquet('analysis_data_step30_on_newest_one.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training / test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data = pd.read_parquet('analysis_data_step30_on_newest_one.parquet')\n",
    "analysis_data = analysis_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2343, 54), (261, 54), (2343, 1), (261, 1))\n"
     ]
    }
   ],
   "source": [
    "X_data, X_test, y_data, y_test = divide_data(analysis_data, analysis_data.drop([\"landslide\"], axis=1).columns, test_size=0.1)\n",
    "full_data = X_data.merge(y_data, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YKlysa\\AppData\\Local\\anaconda3\\envs\\weather\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\YKlysa\\AppData\\Local\\anaconda3\\envs\\weather\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [21 29] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\YKlysa\\AppData\\Local\\anaconda3\\envs\\weather\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "full_up_data = filter_first_features(30, X_data, y_data)\n",
    "new_feats = full_up_data.drop([\"landslide\"], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "len combs = 30\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "((1873, 29), (470, 29), (1873, 1), (470, 1))\n",
      "indxs = Index([29, 13], dtype='int64')\n",
      "idx = 29\n",
      "28\n",
      "len combs = 29\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "indxs = Index([51, 57], dtype='int64')\n",
      "idx = 51\n",
      "27\n",
      "len combs = 28\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "indxs = Index([67, 76], dtype='int64')\n",
      "idx = 67\n",
      "26\n",
      "len combs = 27\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "indxs = Index([111, 109], dtype='int64')\n",
      "idx = 111\n",
      "idx = 109\n",
      "idx = 76\n",
      "26\n",
      "len combs = 27\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "indxs = Index([139, 115], dtype='int64')\n",
      "idx = 139\n",
      "idx = 115\n",
      "idx = 57\n",
      "27\n",
      "len combs = 28\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "indxs = Index([156, 145], dtype='int64')\n",
      "idx = 156\n",
      "26\n",
      "len combs = 27\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "indxs = Index([189, 191], dtype='int64')\n",
      "idx = 189\n",
      "idx = 191\n",
      "idx = 145\n",
      "26\n",
      "len combs = 27\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "indxs = Index([196, 211], dtype='int64')\n",
      "idx = 196\n",
      "idx = 211\n",
      "idx = 13\n",
      "28\n",
      "len combs = 29\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "((1873, 28), (470, 28), (1873, 1), (470, 1))\n",
      "indxs = Index([248, 251], dtype='int64')\n",
      "idx = 248\n",
      "27\n",
      "len combs = 28\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "indxs = Index([276, 272], dtype='int64')\n",
      "idx = 276\n",
      "26\n",
      "len combs = 27\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "indxs = Index([297, 293], dtype='int64')\n",
      "idx = 297\n",
      "idx = 293\n",
      "idx = 272\n",
      "26\n",
      "len combs = 27\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "indxs = Index([310, 333], dtype='int64')\n",
      "idx = 310\n",
      "idx = 333\n",
      "idx = 251\n",
      "27\n",
      "len combs = 28\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "((1873, 27), (470, 27), (1873, 1), (470, 1))\n",
      "indxs = Index([338, 346], dtype='int64')\n",
      "idx = 338\n",
      "26\n",
      "len combs = 27\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "indxs = Index([377, 378], dtype='int64')\n",
      "idx = 377\n",
      "idx = 378\n",
      "idx = 346\n",
      "26\n",
      "len combs = 27\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "((1873, 26), (470, 26), (1873, 1), (470, 1))\n",
      "indxs = Index([402, 404], dtype='int64')\n",
      "idx = 402\n",
      "idx = 404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>prev_index</th>\n",
       "      <th>rf_acc_train</th>\n",
       "      <th>rf_prec_1_train</th>\n",
       "      <th>rf_rec_1_train</th>\n",
       "      <th>rf_f1_1_train</th>\n",
       "      <th>rf_acc</th>\n",
       "      <th>rf_prec_1</th>\n",
       "      <th>rf_rec_1</th>\n",
       "      <th>rf_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[prec_max, prec_mean, prec_min, prec_kurt, sum...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938067</td>\n",
       "      <td>0.967626</td>\n",
       "      <td>0.715426</td>\n",
       "      <td>0.822630</td>\n",
       "      <td>0.917021</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[prec_max, prec_mean, prec_min, prec_kurt, sum...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939135</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.718085</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.912766</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[prec_max, prec_mean, prec_min, prec_kurt, sum...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.940203</td>\n",
       "      <td>0.974820</td>\n",
       "      <td>0.720745</td>\n",
       "      <td>0.828746</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[prec_max, prec_mean, prec_min, prec_kurt, sum...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935398</td>\n",
       "      <td>0.960289</td>\n",
       "      <td>0.707447</td>\n",
       "      <td>0.814701</td>\n",
       "      <td>0.917021</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.757764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[prec_max, prec_mean, prec_min, prec_kurt, sum...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938067</td>\n",
       "      <td>0.967626</td>\n",
       "      <td>0.715426</td>\n",
       "      <td>0.822630</td>\n",
       "      <td>0.912766</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>[prec_mean, prec_min, prec_kurt, sum_prec, win...</td>\n",
       "      <td>346</td>\n",
       "      <td>0.945542</td>\n",
       "      <td>0.989286</td>\n",
       "      <td>0.736702</td>\n",
       "      <td>0.844512</td>\n",
       "      <td>0.921277</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.761290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>[prec_mean, prec_min, prec_kurt, sum_prec_mont...</td>\n",
       "      <td>346</td>\n",
       "      <td>0.946076</td>\n",
       "      <td>0.975779</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.848120</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.746835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>[prec_mean, prec_min, sum_prec, sum_prec_month...</td>\n",
       "      <td>346</td>\n",
       "      <td>0.946076</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.847201</td>\n",
       "      <td>0.917021</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>0.748387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>[prec_mean, prec_kurt, sum_prec, sum_prec_mont...</td>\n",
       "      <td>346</td>\n",
       "      <td>0.947144</td>\n",
       "      <td>0.982578</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.850679</td>\n",
       "      <td>0.923404</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.642105</td>\n",
       "      <td>0.772152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>[prec_min, prec_kurt, sum_prec, sum_prec_month...</td>\n",
       "      <td>346</td>\n",
       "      <td>0.947144</td>\n",
       "      <td>0.972696</td>\n",
       "      <td>0.757979</td>\n",
       "      <td>0.852018</td>\n",
       "      <td>0.917021</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              features  prev_index  \\\n",
       "0    [prec_max, prec_mean, prec_min, prec_kurt, sum...           0   \n",
       "1    [prec_max, prec_mean, prec_min, prec_kurt, sum...           0   \n",
       "2    [prec_max, prec_mean, prec_min, prec_kurt, sum...           0   \n",
       "3    [prec_max, prec_mean, prec_min, prec_kurt, sum...           0   \n",
       "4    [prec_max, prec_mean, prec_min, prec_kurt, sum...           0   \n",
       "..                                                 ...         ...   \n",
       "411  [prec_mean, prec_min, prec_kurt, sum_prec, win...         346   \n",
       "412  [prec_mean, prec_min, prec_kurt, sum_prec_mont...         346   \n",
       "413  [prec_mean, prec_min, sum_prec, sum_prec_month...         346   \n",
       "414  [prec_mean, prec_kurt, sum_prec, sum_prec_mont...         346   \n",
       "415  [prec_min, prec_kurt, sum_prec, sum_prec_month...         346   \n",
       "\n",
       "     rf_acc_train  rf_prec_1_train  rf_rec_1_train  rf_f1_1_train    rf_acc  \\\n",
       "0        0.938067         0.967626        0.715426       0.822630  0.917021   \n",
       "1        0.939135         0.971223        0.718085       0.825688  0.912766   \n",
       "2        0.940203         0.974820        0.720745       0.828746  0.914894   \n",
       "3        0.935398         0.960289        0.707447       0.814701  0.917021   \n",
       "4        0.938067         0.967626        0.715426       0.822630  0.912766   \n",
       "..            ...              ...             ...            ...       ...   \n",
       "411      0.945542         0.989286        0.736702       0.844512  0.921277   \n",
       "412      0.946076         0.975779        0.750000       0.848120  0.914894   \n",
       "413      0.946076         0.982456        0.744681       0.847201  0.917021   \n",
       "414      0.947144         0.982578        0.750000       0.850679  0.923404   \n",
       "415      0.947144         0.972696        0.757979       0.852018  0.917021   \n",
       "\n",
       "     rf_prec_1  rf_rec_1   rf_f1_1  \n",
       "0     0.937500  0.631579  0.754717  \n",
       "1     0.921875  0.621053  0.742138  \n",
       "2     0.923077  0.631579  0.750000  \n",
       "3     0.924242  0.642105  0.757764  \n",
       "4     0.921875  0.621053  0.742138  \n",
       "..         ...       ...       ...  \n",
       "411   0.983333  0.621053  0.761290  \n",
       "412   0.936508  0.621053  0.746835  \n",
       "413   0.966667  0.610526  0.748387  \n",
       "414   0.968254  0.642105  0.772152  \n",
       "415   0.937500  0.631579  0.754717  \n",
       "\n",
       "[416 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics_try = {'features': [], 'prev_index': [], 'rf_acc_train': [], 'rf_prec_1_train': [], 'rf_rec_1_train': [], 'rf_f1_1_train': [], 'rf_acc': [], 'rf_prec_1': [], 'rf_rec_1': [], 'rf_f1_1': []}\n",
    "new_stats = pd.DataFrame.from_dict(run_feat_sel(full_up_data, new_feats, statistics_try, 29, 0, 25))\n",
    "new_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>prev_index</th>\n",
       "      <th>rf_acc_train</th>\n",
       "      <th>rf_prec_1_train</th>\n",
       "      <th>rf_rec_1_train</th>\n",
       "      <th>rf_f1_1_train</th>\n",
       "      <th>rf_acc</th>\n",
       "      <th>rf_prec_1</th>\n",
       "      <th>rf_rec_1</th>\n",
       "      <th>rf_f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>[prec_mean, prec_kurt, sum_prec, sum_prec_mont...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.947678</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>0.760638</td>\n",
       "      <td>0.853731</td>\n",
       "      <td>0.929787</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.792453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>[prec_mean, prec_kurt, sum_prec, sum_prec_mont...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.947144</td>\n",
       "      <td>0.972696</td>\n",
       "      <td>0.757979</td>\n",
       "      <td>0.852018</td>\n",
       "      <td>0.929787</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.792453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>[prec_mean, prec_kurt, sum_prec, sum_prec_mont...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.947144</td>\n",
       "      <td>0.972696</td>\n",
       "      <td>0.757979</td>\n",
       "      <td>0.852018</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>[prec_mean, prec_kurt, sum_prec, sum_prec_mont...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.940737</td>\n",
       "      <td>0.955326</td>\n",
       "      <td>0.739362</td>\n",
       "      <td>0.833583</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[prec_mean, prec_kurt, sum_prec_month, wind_ma...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.946610</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.763298</td>\n",
       "      <td>0.851632</td>\n",
       "      <td>0.919149</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.768293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              features  prev_index  \\\n",
       "189  [prec_mean, prec_kurt, sum_prec, sum_prec_mont...         156   \n",
       "191  [prec_mean, prec_kurt, sum_prec, sum_prec_mont...         156   \n",
       "190  [prec_mean, prec_kurt, sum_prec, sum_prec_mont...         156   \n",
       "179  [prec_mean, prec_kurt, sum_prec, sum_prec_mont...         156   \n",
       "193  [prec_mean, prec_kurt, sum_prec_month, wind_ma...         156   \n",
       "\n",
       "     rf_acc_train  rf_prec_1_train  rf_rec_1_train  rf_f1_1_train    rf_acc  \\\n",
       "189      0.947678         0.972789        0.760638       0.853731  0.929787   \n",
       "191      0.947144         0.972696        0.757979       0.852018  0.929787   \n",
       "190      0.947144         0.972696        0.757979       0.852018  0.925532   \n",
       "179      0.940737         0.955326        0.739362       0.833583  0.925532   \n",
       "193      0.946610         0.963087        0.763298       0.851632  0.919149   \n",
       "\n",
       "     rf_prec_1  rf_rec_1   rf_f1_1  \n",
       "189   0.984375  0.663158  0.792453  \n",
       "191   0.984375  0.663158  0.792453  \n",
       "190   0.954545  0.663158  0.782609  \n",
       "179   0.954545  0.663158  0.782609  \n",
       "193   0.913043  0.663158  0.768293  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_stats[new_stats.rf_rec_1 > new_stats.rf_rec_1.max()-0.01][['rf_acc_train', 'rf_prec_1_train', 'rf_rec_1_train', 'rf_f1_1_train', 'rf_acc', 'rf_prec_1', 'rf_rec_1', 'rf_f1_1']].plot()\n",
    "new_stats[new_stats.rf_rec_1 > new_stats.rf_rec_1.max()-0.01].sort_values(by=['rf_rec_1', 'rf_f1_1', 'rf_prec_1', 'rf_acc', 'rf_f1_1_train', 'rf_prec_1_train', 'rf_rec_1_train', 'rf_acc_train', 'prev_index'], ascending=False)#.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 420 candidates, totalling 1260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YKlysa\\AppData\\Local\\anaconda3\\envs\\weather\\lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.655058</td>\n",
       "      <td>0.116765</td>\n",
       "      <td>0.127216</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>400</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'gini', 'max...</td>\n",
       "      <td>0.916773</td>\n",
       "      <td>0.912932</td>\n",
       "      <td>0.911652</td>\n",
       "      <td>0.913786</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10.020590</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>0.188997</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>600</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'gini', 'max...</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.911652</td>\n",
       "      <td>0.912932</td>\n",
       "      <td>0.913359</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>13.931440</td>\n",
       "      <td>0.295151</td>\n",
       "      <td>0.216866</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>False</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>700</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'log_loss', ...</td>\n",
       "      <td>0.912932</td>\n",
       "      <td>0.912932</td>\n",
       "      <td>0.914213</td>\n",
       "      <td>0.913359</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.030781</td>\n",
       "      <td>0.059365</td>\n",
       "      <td>0.098443</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'gini', 'max...</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.912932</td>\n",
       "      <td>0.911652</td>\n",
       "      <td>0.913359</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>12.050322</td>\n",
       "      <td>0.213705</td>\n",
       "      <td>0.192795</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>False</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>12</td>\n",
       "      <td>log2</td>\n",
       "      <td>600</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'log_loss', ...</td>\n",
       "      <td>0.912932</td>\n",
       "      <td>0.914213</td>\n",
       "      <td>0.911652</td>\n",
       "      <td>0.912932</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>14.603457</td>\n",
       "      <td>0.123332</td>\n",
       "      <td>0.068318</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>False</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'log_loss', ...</td>\n",
       "      <td>0.759283</td>\n",
       "      <td>0.781050</td>\n",
       "      <td>0.869398</td>\n",
       "      <td>0.803244</td>\n",
       "      <td>0.047615</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>19.652548</td>\n",
       "      <td>0.279268</td>\n",
       "      <td>0.091087</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>False</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>400</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'log_loss', ...</td>\n",
       "      <td>0.759283</td>\n",
       "      <td>0.781050</td>\n",
       "      <td>0.869398</td>\n",
       "      <td>0.803244</td>\n",
       "      <td>0.047615</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>24.766289</td>\n",
       "      <td>0.495110</td>\n",
       "      <td>0.111950</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>False</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'log_loss', ...</td>\n",
       "      <td>0.759283</td>\n",
       "      <td>0.781050</td>\n",
       "      <td>0.869398</td>\n",
       "      <td>0.803244</td>\n",
       "      <td>0.047615</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>29.167599</td>\n",
       "      <td>0.878196</td>\n",
       "      <td>0.165791</td>\n",
       "      <td>0.027934</td>\n",
       "      <td>False</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>600</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'log_loss', ...</td>\n",
       "      <td>0.759283</td>\n",
       "      <td>0.781050</td>\n",
       "      <td>0.869398</td>\n",
       "      <td>0.803244</td>\n",
       "      <td>0.047615</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>24.170491</td>\n",
       "      <td>0.977027</td>\n",
       "      <td>0.079315</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>False</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'log_loss', ...</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.836108</td>\n",
       "      <td>0.755442</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.034405</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "91        6.655058      0.116765         0.127216        0.007871   \n",
       "93       10.020590      0.118038         0.188997        0.003509   \n",
       "199      13.931440      0.295151         0.216866        0.007804   \n",
       "90        5.030781      0.059365         0.098443        0.001347   \n",
       "198      12.050322      0.213705         0.192795        0.007116   \n",
       "..             ...           ...              ...             ...   \n",
       "115      14.603457      0.123332         0.068318        0.003937   \n",
       "116      19.652548      0.279268         0.091087        0.000405   \n",
       "117      24.766289      0.495110         0.111950        0.000322   \n",
       "118      29.167599      0.878196         0.165791        0.027934   \n",
       "160      24.170491      0.977027         0.079315        0.001202   \n",
       "\n",
       "    param_bootstrap param_criterion param_max_depth param_max_features  \\\n",
       "91            False            gini              12               log2   \n",
       "93            False            gini              12               log2   \n",
       "199           False        log_loss              12               log2   \n",
       "90            False            gini              12               log2   \n",
       "198           False        log_loss              12               log2   \n",
       "..              ...             ...             ...                ...   \n",
       "115           False        log_loss               4               None   \n",
       "116           False        log_loss               4               None   \n",
       "117           False        log_loss               4               None   \n",
       "118           False        log_loss               4               None   \n",
       "160           False        log_loss               7               None   \n",
       "\n",
       "    param_n_estimators                                             params  \\\n",
       "91                 400  {'bootstrap': False, 'criterion': 'gini', 'max...   \n",
       "93                 600  {'bootstrap': False, 'criterion': 'gini', 'max...   \n",
       "199                700  {'bootstrap': False, 'criterion': 'log_loss', ...   \n",
       "90                 300  {'bootstrap': False, 'criterion': 'gini', 'max...   \n",
       "198                600  {'bootstrap': False, 'criterion': 'log_loss', ...   \n",
       "..                 ...                                                ...   \n",
       "115                300  {'bootstrap': False, 'criterion': 'log_loss', ...   \n",
       "116                400  {'bootstrap': False, 'criterion': 'log_loss', ...   \n",
       "117                500  {'bootstrap': False, 'criterion': 'log_loss', ...   \n",
       "118                600  {'bootstrap': False, 'criterion': 'log_loss', ...   \n",
       "160                300  {'bootstrap': False, 'criterion': 'log_loss', ...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "91            0.916773           0.912932           0.911652         0.913786   \n",
       "93            0.915493           0.911652           0.912932         0.913359   \n",
       "199           0.912932           0.912932           0.914213         0.913359   \n",
       "90            0.915493           0.912932           0.911652         0.913359   \n",
       "198           0.912932           0.914213           0.911652         0.912932   \n",
       "..                 ...                ...                ...              ...   \n",
       "115           0.759283           0.781050           0.869398         0.803244   \n",
       "116           0.759283           0.781050           0.869398         0.803244   \n",
       "117           0.759283           0.781050           0.869398         0.803244   \n",
       "118           0.759283           0.781050           0.869398         0.803244   \n",
       "160           0.816901           0.836108           0.755442         0.802817   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "91         0.002176                1  \n",
       "93         0.001597                2  \n",
       "199        0.000604                2  \n",
       "90         0.001597                4  \n",
       "198        0.001045                5  \n",
       "..              ...              ...  \n",
       "115        0.047615              415  \n",
       "116        0.047615              415  \n",
       "117        0.047615              415  \n",
       "118        0.047615              415  \n",
       "160        0.034405              420  \n",
       "\n",
       "[420 rows x 16 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hyperp_tuning(X, y):\n",
    "    params = {'bootstrap': [False, True], #True\n",
    "            'criterion':['gini', 'log_loss'], #, 'log_loss'\n",
    "    'max_depth': [4, 5, 6, 7, 8, 10, 12], #, 10, 40, 50, 60    , 30, None\n",
    "    'max_features': ['log2', 'sqrt', None],  #, 'sqrt', None\n",
    "    #  'min_samples_leaf': [1, 2, 4],\n",
    "    #  'min_samples_split': [2, 5, 10], #10, 5\n",
    "    'n_estimators': [300, 400, 500, 600, 700]} #, 1200, 2000, 1000, 1600     200, 600, 800,200, 400, \n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = params, cv = 3, n_jobs = -1, verbose = 2, refit='recall')\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search\n",
    "\n",
    "new_feats = new_stats.iloc[191].features\n",
    "grid_search = hyperp_tuning(X_data[new_feats], y_data)\n",
    "pd.DataFrame.from_dict(grid_search.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 12,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 400}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YKlysa\\AppData\\Local\\anaconda3\\envs\\weather\\lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9233716475095786\n",
      "Confusion Matrix:\n",
      "[[206   2]\n",
      " [ 18  35]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       208\n",
      "           1       0.95      0.66      0.78        53\n",
      "\n",
      "    accuracy                           0.92       261\n",
      "   macro avg       0.93      0.83      0.87       261\n",
      "weighted avg       0.92      0.92      0.92       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_after_grid = RandomForestClassifier(random_state=42, class_weight=\"balanced\", **grid_search.best_params_)\n",
    "rf_after_grid.fit(X_data[new_feats], y_data)\n",
    "y_predict = rf_after_grid.predict(X_test[new_feats])\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_predict)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl_file = \"rf_trained_step30_after_grid_on_lat_points_inv.pkl\" \n",
    "\n",
    "# with open(model_pkl_file, 'wb') as file:  \n",
    "#     pickle.dump(rf_after_grid, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
